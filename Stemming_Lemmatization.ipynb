{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fatis092/repo52/blob/main/Stemming_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries\n"
      ],
      "metadata": {
        "id": "ii9sd-Nn_TTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "UMvRNmdk_Wng"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading necessary NLTK resources\n"
      ],
      "metadata": {
        "id": "FeOOYe46_YWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "L3KxSNJj_WjZ",
        "outputId": "7fb00d3a-f29d-4043-8853-173d61459df4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample text"
      ],
      "metadata": {
        "id": "DXNU9Vic_apO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The leaves on the trees are falling. The children are playing with leaves in the park.\"\n"
      ],
      "metadata": {
        "id": "F_5JHYrp_WgO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing the text into words\n"
      ],
      "metadata": {
        "id": "zoFDGkGn_cVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)\n"
      ],
      "metadata": {
        "id": "vVcVhtNo_WaO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Stemming\n"
      ],
      "metadata": {
        "id": "TIXusxPl_ecC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(\"Stemmed Words: \", stemmed_words)"
      ],
      "metadata": {
        "id": "puov6nZD_WWF",
        "outputId": "a8789742-2a2b-4af1-a1b4-d817bf4fcea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words:  ['the', 'leav', 'on', 'the', 'tree', 'are', 'fall', '.', 'the', 'children', 'are', 'play', 'with', 'leav', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Lemmatization\n"
      ],
      "metadata": {
        "id": "gjDs9Pmc_gTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "dsqyCAUr_i3f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get part of speech tags compatible with WordNet\n"
      ],
      "metadata": {
        "id": "5t24WQ99_ksc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "kgDD2hM__mhG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
        "print(\"Lemmatized Words: \", lemmatized_words)"
      ],
      "metadata": {
        "id": "6SgHxLJJ_tI7",
        "outputId": "48f498a4-76b0-4f19-987b-2be6dbd72abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words:  ['The', 'leaf', 'on', 'the', 'tree', 'be', 'fall', '.', 'The', 'child', 'be', 'play', 'with', 'leaf', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare original, stemmed, and lemmatized words\n"
      ],
      "metadata": {
        "id": "-ry54fxp_vfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gtKW6Vk4_Km2",
        "outputId": "c17429a4-2600-4b40-b4a9-b6e2d67f34c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison (Original, Stemmed, Lemmatized):\n",
            "The             -> the             -> The            \n",
            "leaves          -> leav            -> leaf           \n",
            "on              -> on              -> on             \n",
            "the             -> the             -> the            \n",
            "trees           -> tree            -> tree           \n",
            "are             -> are             -> be             \n",
            "falling         -> fall            -> fall           \n",
            ".               -> .               -> .              \n",
            "The             -> the             -> The            \n",
            "children        -> children        -> child          \n",
            "are             -> are             -> be             \n",
            "playing         -> play            -> play           \n",
            "with            -> with            -> with           \n",
            "leaves          -> leav            -> leaf           \n",
            "in              -> in              -> in             \n",
            "the             -> the             -> the            \n",
            "park            -> park            -> park           \n",
            ".               -> .               -> .              \n"
          ]
        }
      ],
      "source": [
        "comparison = list(zip(words, stemmed_words, lemmatized_words))\n",
        "print(\"\\nComparison (Original, Stemmed, Lemmatized):\")\n",
        "for original, stemmed, lemmatized in comparison:\n",
        "    print(f\"{original:15} -> {stemmed:15} -> {lemmatized:15}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import PorterStemmer\n"
      ],
      "metadata": {
        "id": "JzVXuFXr_yVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "E3VD3gwV_4pi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to stem\n"
      ],
      "metadata": {
        "id": "vN9xnoxH_5me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "H0F65z_a_7GW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the stemmer"
      ],
      "metadata": {
        "id": "V3TrYFTr_9G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "JDAQYVcq_83z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Stem each word and print the result\n"
      ],
      "metadata": {
        "id": "9gbg_-WF__cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "print(\"Stemmed Words:\", stemmed_words)\n"
      ],
      "metadata": {
        "id": "n3ByrzKu_VAw",
        "outputId": "0a9904e1-de5a-4e25-aee8-f8da1222b000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['run', 'jump', 'easili', 'fli']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import WordNetLemmatizer and other necessary modules\n"
      ],
      "metadata": {
        "id": "9v_oNGh8ABmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n"
      ],
      "metadata": {
        "id": "FK5TnQicAGK7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to lemmatize\n"
      ],
      "metadata": {
        "id": "gqykQJbXAG7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "EhavRpJLAHzg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the lemmatizer\n"
      ],
      "metadata": {
        "id": "JYJ0jgB_AIym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "tNAQ7KTcAJtZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper function to get WordNet PoS tag\n"
      ],
      "metadata": {
        "id": "svvQAi75AKWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "gV61RG-3ALb0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Lemmatize each word with PoS tag and print the result\n"
      ],
      "metadata": {
        "id": "8XXYt1N_ANNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "# Assuming 'words' is a list of words you want to lemmatize\n",
        "words = [\"running\", \"cats\", \"better\"]  # Example list, replace with your actual list\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
        "\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n"
      ],
      "metadata": {
        "id": "RLuE1fcyAEBW",
        "outputId": "608256db-6a1d-4c40-971b-238fe1effbeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Lemmatized Words: ['run', 'cat', 'well']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}