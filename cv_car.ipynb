{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7133129,
          "sourceType": "datasetVersion",
          "datasetId": 4115709
        }
      ],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "cv car ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fatis092/repo52/blob/main/cv_car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'cv-car-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4115709%2F7133129%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240903%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240903T104035Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7614216a59c0ead31e31598a8c4bd40b79ff6d53da731d6320e3794c546c9637d180d25fcc759792cba31b87cfebeab84da823073279ad14e7b68b526f4aea520764adb107a2142fa50de9a2a63d31165ad3c9f6504d18e02f6a5f64c2e3a36a5407a24a12d78e90301fa8045c92c98365be0cb09da7fdca3ec13251d733f1ff7c0b67e701e91c5623d478d9a4c85ff76499b1201f541180bcea5eddc99235107cf0e343605d80fcfa56068f335ce208f4e6a8bac6e1f4d2376af764ea30c5203ef831a19b1a766d2f327695f68321ce5e0a20c2b0fb872d5c2dec23045693f44082aeccf0a4560c6e23ab1f1f7f69e5cf1241f1563ef07fb605b9038e7ea31c'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "vIKWqxPXgr-q"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The computer vision project uses machine learning, radar technology, and OCR to analyze Egyptian license plates ðŸš˜. EasyOCR library is employed for Arabic OCR. The code processes images, detects plate edges, and uses OCR for text. The results are displayed visually, demonstrating the integration of computer vision and OCR for license plate analysis. ðŸš˜ðŸš˜"
      ],
      "metadata": {
        "id": "8qHSpMl3gr-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Import librarys necessary to done the project"
      ],
      "metadata": {
        "id": "ML0MRzjNgr-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from easyocr import Reader\n",
        "import cv2\n",
        "import matplotlib.pylab as plt"
      ],
      "metadata": {
        "id": "I2984IH4gr-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Reading the data set file"
      ],
      "metadata": {
        "id": "oRRAIhwSgr-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = 'C:/Users/alabdeen/Desktop/project cv/data3'"
      ],
      "metadata": {
        "id": "6K6wbNA_gr-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - This line prepares an OCR reader in the Arabic programming language using a central processing unit (CPU) and without printing details of internal operations."
      ],
      "metadata": {
        "id": "nDsaLdORgr-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(['ar'], gpu=False, verbose=False)"
      ],
      "metadata": {
        "id": "G5Mjm-Whgr-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image upload and processing:\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        car = cv2.imread(image_path)\n",
        "        car = cv2.resize(car, (800, 600))\n",
        "\n",
        "        # Image processing for edge detection\n",
        "        \"\"\"\n",
        "        The image is converted to grayscale and smoothed using a Gaussian Blur filter.\n",
        "        Canny technology is then used to detect the edges of the board.\n",
        "        \"\"\"\n",
        "        gray = cv2.cvtColor(car, cv2.COLOR_BGR2GRAY)\n",
        "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "        edged = cv2.Canny(blur, 10, 200)\n",
        "\n",
        "        # Identify the panel:\n",
        "        \"\"\"\n",
        "        The Contours technique is used to identify edges, and the five largest edges are selected.\n",
        "        The plate is defined by searching for approximate polygons after finding the edge.\n",
        "        \"\"\"\n",
        "        cont, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cont = sorted(cont, key=cv2.contourArea, reverse=True)[:5]\n",
        "        plate_cnt = None\n",
        "        for c in cont:\n",
        "            arc = cv2.arcLength(c, True)\n",
        "            approx = cv2.approxPolyDP(c, 0.02 * arc, True)\n",
        "            if len(approx) == 4:\n",
        "                plate_cnt = approx\n",
        "                break\n",
        "\n",
        "        # Read text from panel using OCR:\n",
        "        \"\"\"\n",
        "        If the plate is found, OCR is used to read the text.\n",
        "        If no text is readable, a message indicating that the text is difficult to read is displayed on the panel.\n",
        "        If the text is read successfully, it is displayed on the image with the panel selected.\n",
        "        \"\"\"\n",
        "        if plate_cnt is not None:\n",
        "            (x, y, w, h) = cv2.boundingRect(plate_cnt)\n",
        "            x = max(0, x)\n",
        "            y = max(0, y)\n",
        "            plate_roi = gray[y:y + h, x:x + w]\n",
        "\n",
        "            detection = reader.readtext(plate_roi)\n",
        "\n",
        "            if len(detection) == 0:\n",
        "                text = \"Impossible to read the text from the license plate\"\n",
        "                cv2.putText(car, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 3)\n",
        "            else:\n",
        "                cv2.drawContours(car, [plate_cnt], -1, (255, 0, 0), 3)\n",
        "                text = f\"{detection[0][1]} {detection[0][2] * 100:.2f}%\"\n",
        "                cv2.putText(car, text, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
        "                print(text)\n",
        "\n",
        "        # Display the original image\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(cv2.cvtColor(car, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Image\")\n",
        "\n",
        "        # If the board is found, display a thumbnail of the board\n",
        "        if plate_cnt is not None:\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(cv2.cvtColor(plate_roi, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(\"License Plate\")\n",
        "\n",
        "            # Display the original image with the panel selected\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(cv2.cvtColor(car, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(\"Image with Contours\")\n",
        "\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "NbtqN-ZBgr-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XW4pEQimgr-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}